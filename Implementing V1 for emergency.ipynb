{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#importing req library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "#Importing libraries for defining the architechure\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import adam\n",
    "from torch.nn import ReLU,BCELoss,Sequential,Sigmoid,Linear\n",
    "\n",
    "#importing torch vision\n",
    "from torchvision.models import googlenet\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a70d795adcc741f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))  # 0 corresponds to the first GPU"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "978f9162b30a3464"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Loading and pre-processing the Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6e44d7974ebf971"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "csv_path=\"G:\\\\NN\\\\Assment\\\\Emergency and non emergency vechile clasification\\\\Dataset\\\\emergency_classification.csv\"\n",
    "img_dir='G:/NN/Assment/Emergency and non emergency vechile clasification/Dataset/images/'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d3cb1a8125276d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#defining the preprocessing steps\n",
    "normalize=transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                               std=[0.229,0.224,0.225])\n",
    "preprocessing=transforms.Compose([transforms.ToTensor(),normalize])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b51aff271b1465a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# defining the class to load dataset \n",
    "class EmergencyDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading Emergency Dataset\"\"\"\n",
    "\n",
    "    # defining the init function\n",
    "    def __init__(self, csv_path, img_dir, transform):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.csv_path = csv_path\n",
    "        self.img_names = df.image_names.values\n",
    "        self.y = df['emergency_or_not'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    # defining the get item function\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_dir + self.img_names[index])\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    # defining the len function\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c87d44574caf29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "train_dataset = EmergencyDataset(csv_path,img_dir,\n",
    "                              transform=preprocessing)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee864e364690a6dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#loading the data in batch using dataloader\n",
    "trainloader=DataLoader(dataset=train_dataset,\n",
    "                       batch_size=45,\n",
    "                       shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30bb682b30e0da1c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for batch_idx ,(batch_x,batch_y)in enumerate(trainloader):\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f8c3c0dd894aef0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#shape of the label\n",
    "batch_x.shape,batch_y.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ace66762063427a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  loading the weights of the pre trained model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8566671187e6d2b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define model architecture along with pretrained weights of googlenet / inception_v1\n",
    "googlenet_model=googlenet(pretrained=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e8cbf223d82e8b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print the model\n",
    "googlenet_model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6edb585c7e5fcb0c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# architecture in form of a list\n",
    "list(googlenet_model.children())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3c5ccd007820326"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#defining the extract model\n",
    "class FreatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FreatureExtractor,self).__init__()\n",
    "        #push to cuda\n",
    "        if torch.cuda.is_available():\n",
    "            self.net=self.net.cuda()\n",
    "        for p in self.net.parameters():\n",
    "            p.requires_grad=False\n",
    "            # Define which layers you are going to extract\n",
    "        self.feauters=nn.Sequential(*list(self.net.childern())[:-3])\n",
    "    def froward(self,x):\n",
    "        return self.feauters(x)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b22f02729612776"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# prepare input\n",
    "input = batch_x[:2]\n",
    "input = input.cuda()\n",
    "\n",
    "# pass the input to vgg16\n",
    "if __name__ == \"__main__\":\n",
    "    fe = FeatureExtractor()\n",
    "    output = fe(input)\n",
    "\n",
    "# shape of the output\n",
    "output.shape\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d0c5b98e4e58b1f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!conda install pytorch torchvision torchaudio cudatoolkit=12.3 -c pytorch\n",
    "\n",
    " conda install conda=24.1.0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e11d5a776e25b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#shape of output\n",
    "output.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6c76a6a3bed41e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69ea709dd040b9ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "40d31ab1297ce3a6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
