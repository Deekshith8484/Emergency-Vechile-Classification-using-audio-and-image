{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a70d795adcc741f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing req library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "#Importing libraries for defining the architechure\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import adam\n",
    "from torch.nn import ReLU,BCELoss,Sequential,Sigmoid,Linear\n",
    "\n",
    "#importing torch vision\n",
    "from torchvision.models import googlenet\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e44d7974ebf971",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##  Loading and pre-processing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d3cb1a8125276d7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_path=\"G:\\\\NN\\\\Assment\\\\Emergency and non emergency vechile clasification\\\\Dataset\\\\emergency_classification.csv\"\n",
    "img_dir='G:/NN/Assment/Emergency and non emergency vechile clasification/Dataset/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b51aff271b1465a1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#defining the preprocessing steps\n",
    "normalize=transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                               std=[0.229,0.224,0.225])\n",
    "preprocessing=transforms.Compose([transforms.ToTensor(),normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c87d44574caf29",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# defining the class to load dataset \n",
    "class EmergencyDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading Emergency Dataset\"\"\"\n",
    "\n",
    "    # defining the init function\n",
    "    def __init__(self, csv_path, img_dir, transform):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.csv_path = csv_path\n",
    "        self.img_names = df.image_names.values\n",
    "        self.y = df['emergency_or_not'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    # defining the get item function\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_dir + self.img_names[index])\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    # defining the len function\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee864e364690a6dc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "train_dataset = EmergencyDataset(csv_path,img_dir,\n",
    "                              transform=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30bb682b30e0da1c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loading the data in batch using dataloader\n",
    "trainloader=DataLoader(dataset=train_dataset,\n",
    "                       batch_size=45,\n",
    "                       shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5f8c3c0dd894aef0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for batch_idx ,(batch_x,batch_y)in enumerate(trainloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ace66762063427a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([45, 3, 224, 224]), torch.Size([45]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of the label\n",
    "batch_x.shape,batch_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8566671187e6d2b3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##  loading the weights of the pre trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e8cbf223d82e8b6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define model architecture along with pretrained weights of googlenet / inception_v1\n",
    "googlenet_model=googlenet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6edb585c7e5fcb0c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): BasicConv2d(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (conv2): BasicConv2d(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): BasicConv2d(\n",
       "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception3a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception3b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception4a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4c): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4d): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4e): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception5a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception5b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (aux1): None\n",
       "  (aux2): None\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the model\n",
    "googlenet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b3c5ccd007820326",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BasicConv2d(\n",
       "   (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "   (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True),\n",
       " BasicConv2d(\n",
       "   (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " BasicConv2d(\n",
       "   (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True),\n",
       " Inception(\n",
       "   (branch1): BasicConv2d(\n",
       "     (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch2): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch3): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch4): Sequential(\n",
       "     (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " Inception(\n",
       "   (branch1): BasicConv2d(\n",
       "     (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch2): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch3): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch4): Sequential(\n",
       "     (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True),\n",
       " Inception(\n",
       "   (branch1): BasicConv2d(\n",
       "     (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch2): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch3): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch4): Sequential(\n",
       "     (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " Inception(\n",
       "   (branch1): BasicConv2d(\n",
       "     (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch2): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch3): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch4): Sequential(\n",
       "     (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " Inception(\n",
       "   (branch1): BasicConv2d(\n",
       "     (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch2): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch3): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch4): Sequential(\n",
       "     (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " Inception(\n",
       "   (branch1): BasicConv2d(\n",
       "     (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch2): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch3): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch4): Sequential(\n",
       "     (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " Inception(\n",
       "   (branch1): BasicConv2d(\n",
       "     (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch2): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch3): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch4): Sequential(\n",
       "     (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True),\n",
       " Inception(\n",
       "   (branch1): BasicConv2d(\n",
       "     (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch2): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch3): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch4): Sequential(\n",
       "     (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " Inception(\n",
       "   (branch1): BasicConv2d(\n",
       "     (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch2): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch3): Sequential(\n",
       "     (0): BasicConv2d(\n",
       "       (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (branch4): Sequential(\n",
       "     (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "     (1): BasicConv2d(\n",
       "       (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " AdaptiveAvgPool2d(output_size=(1, 1)),\n",
       " Dropout(p=0.2, inplace=False),\n",
       " Linear(in_features=1024, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# architecture in form of a list\n",
    "list(googlenet_model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b22f02729612776",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# defining the class to extract features\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.net = googlenet(pretrained=True)\n",
    "        #push to cuda\n",
    "        if torch.cuda.is_available():\n",
    "            self.net = self.net.cuda()\n",
    "        for p in self.net.parameters():\n",
    "            p.requires_grad = False\n",
    "        # Define which layers you are going to extract\n",
    "        self.features = nn.Sequential(*list(self.net.children())[:-3])        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d0c5b98e4e58b1f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1024, 7, 7])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare input\n",
    "input = batch_x[:5]\n",
    "input = input.cuda()\n",
    "\n",
    "# pass the input to vgg16\n",
    "if __name__ == \"__main__\":\n",
    "    fe = FeatureExtractor()\n",
    "    output = fe(input)\n",
    "\n",
    "# shape of the output\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d88bb99",
   "metadata": {},
   "source": [
    "##  Fine tune the model for the current problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a5c4ab",
   "metadata": {},
   "source": [
    "**extract the Feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "40d31ab1297ce3a6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature=[]\n",
    "target=[]\n",
    "time_elapsed=[]\n",
    "#set model to eval\n",
    "googlenet_model.eval()\n",
    "#deactivate auto grad\n",
    "\n",
    "with torch.no_grad():\n",
    "    # getting the data in batches using defined data loader\n",
    "    for batch_idx,(batch_x,batch_y) in enumerate (trainloader):\n",
    "        if torch.cuda.is_available():\n",
    "           batch_x=batch_x.cuda()\n",
    "        #record time for extracting the features\n",
    "        start=torch.cuda.Event(enable_timing=True)\n",
    "        end=torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "        start.record()\n",
    "        #extracting the features\n",
    "        if __name__== \"__main__\":\n",
    "            fe=FeatureExtractor()\n",
    "            batch_features=fe(batch_x)\n",
    "\n",
    "        end.record()\n",
    "        #waits for everything to finish\n",
    "        torch.cuda.synchronize()\n",
    "        #time elapsed\n",
    "        time_elapsed.append(start.elapsed_time(end))\n",
    "        #converting to numpy\n",
    "        batch_features=batch_features.data.cpu().numpy()\n",
    "        # append in list\n",
    "        feature.append(batch_features)\n",
    "        target.append(batch_y)\n",
    "\n",
    "#save to the array\n",
    "feature = np.concatenate(feature, axis=0)\n",
    "target = np.concatenate(target, axis=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b85ae73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  tensor(10.0763)\n"
     ]
    }
   ],
   "source": [
    "# time taken to extract features\n",
    "print('Time taken in seconds: ', torch.sum(torch.tensor(time_elapsed))*0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b41094a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2352, 1024, 7, 7)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the features\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa3741",
   "metadata": {},
   "source": [
    "**Flatting the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "20a7155d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2352, 50176)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flattening the features\n",
    "feature=feature.reshape(len(feature),-1)\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6793e2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((1646, 50176), (1646,)), ((706, 50176), (706,)))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the training and validation data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(feature, target, test_size=0.3, stratify=target, random_state=42)\n",
    "# shape of training and validation set\n",
    "(X_train.shape, y_train.shape), (X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8282b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training and validation set to PyTorch tensor\n",
    "X_train=torch.FloatTensor(X_train)\n",
    "y_train=torch.FloatTensor(y_train)\n",
    "X_valid=torch.FloatTensor(X_valid)\n",
    "y_valid=torch.FloatTensor(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a0fe3d",
   "metadata": {},
   "source": [
    "**Defining the NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c14f0c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential(Linear(1024*7*7,64),\n",
    "                  ReLU(),\n",
    "                  Linear(64,1),\n",
    "                  Sigmoid()\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef8931c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=50176, out_features=64, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (3): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summarry\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9e170c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4488]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass an input to the model to understand the output\n",
    "model(X_train[0].view(1,1024*7*7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7523c363",
   "metadata": {},
   "source": [
    "**Compile model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "691ca03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer and loss function\n",
    "optimizer=torch.optim.Adam(model.parameters())\n",
    "criterion= nn.BCELoss()\n",
    "#checking for gpu\n",
    "if torch.cuda.is_available():\n",
    "    model=model.cuda()\n",
    "    criterion=criterion.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0fa4ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define metric\n",
    "def binary_accuracy(preds, y):\n",
    "  \n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "\n",
    "    #no. of correctly classified    \n",
    "    correct = (rounded_preds == y).float()\n",
    "\n",
    "    #compute accuracy \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c035d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training function\n",
    "def train(X,y,batch_size):\n",
    "\n",
    "  #activate training phase\n",
    "  model.train()\n",
    "  \n",
    "  #initialization\n",
    "  epoch_loss, epoch_acc= 0, 0\n",
    "  no_of_batches = 0\n",
    "\n",
    "  #randomly create indices\n",
    "  indices= torch.randperm(len(X))\n",
    "  \n",
    "  #loading in batches\n",
    "  for i in range(0,len(indices),batch_size):\n",
    "    \n",
    "    #indices for a batch\n",
    "    ind = indices[i:i+batch_size]\n",
    "  \n",
    "    #batch  \n",
    "    batch_x=X[ind]\n",
    "    batch_y=y[ind]\n",
    "    \n",
    "    #push to cuda\n",
    "    if torch.cuda.is_available():\n",
    "        batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "\n",
    "    #clear gradients\n",
    "    optimizer.zero_grad()\n",
    "          \n",
    "    #forward pass\n",
    "    outputs = model(batch_x)\n",
    "\n",
    "    #converting to a 1 dimensional tensor\n",
    "    outputs = outputs.squeeze()\n",
    "\n",
    "    #calculate loss and accuracy\n",
    "    loss = criterion(outputs, batch_y)\n",
    "    acc = binary_accuracy(outputs, batch_y)  \n",
    "    \n",
    "    #Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    #Update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    #Keep track of the loss and accuracy of a epoch\n",
    "    epoch_loss = epoch_loss + loss.item()\n",
    "    epoch_acc  = epoch_acc  + acc.item()\n",
    "\n",
    "    #No. of batches\n",
    "    no_of_batches = no_of_batches+1\n",
    "\n",
    "  return epoch_loss/no_of_batches, epoch_acc/no_of_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e212631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define evaluation function\n",
    "def evaluate(X,y,batch_size):\n",
    "\n",
    "  #deactivate training phase\n",
    "  model.eval()\n",
    "\n",
    "  #initialization\n",
    "  epoch_loss, epoch_acc= 0, 0\n",
    "  no_of_batches = 0\n",
    "\n",
    "  #randomly create indices\n",
    "  indices= torch.randperm(len(X))\n",
    "\n",
    "  #deactivates autograd\n",
    "  with torch.no_grad():\n",
    "    \n",
    "    #loading in batches\n",
    "    for i in range(0,len(indices),batch_size):\n",
    "      \n",
    "      #indices for a batch\n",
    "      ind = indices[i:i+batch_size]\n",
    "  \n",
    "      #batch  \n",
    "      batch_x= X[ind]\n",
    "      batch_y= y[ind]\n",
    "\n",
    "      #push to cuda\n",
    "      if torch.cuda.is_available():\n",
    "          batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "        \n",
    "      #Forward pass\n",
    "      outputs = model(batch_x)\n",
    "\n",
    "      #converting the output to 1 Dimensional tensor\n",
    "      outputs = outputs.squeeze()\n",
    "\n",
    "      # Calculate loss and accuracy\n",
    "      loss = criterion(outputs, batch_y)\n",
    "      acc = binary_accuracy(outputs, batch_y)   \n",
    "      \n",
    "      #keep track of loss and accuracy of an epoch\n",
    "      epoch_loss = epoch_loss + loss.item()\n",
    "      epoch_acc  = epoch_acc  + acc.item()\n",
    "\n",
    "      #no. of batches\n",
    "      no_of_batches = no_of_batches + 1\n",
    "\n",
    "    return epoch_loss/no_of_batches, epoch_acc/no_of_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9bcb4710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define prediction function\n",
    "def predict(X,batch_size):\n",
    "  \n",
    "  #deactivate training phase\n",
    "  model.eval()\n",
    "\n",
    "  # initialization \n",
    "  predictions = []\n",
    "\n",
    "  # create indices\n",
    "  indices = torch.arange(len(X))\n",
    "\n",
    "  #deactivates autograd\n",
    "  with torch.no_grad():\n",
    "      \n",
    "      for i in range(0, len(X), batch_size):\n",
    "        \n",
    "        #indices for a batch\n",
    "        ind = indices[i:i+batch_size]\n",
    "\n",
    "        # batch\n",
    "        batch_x = X[ind]\n",
    "\n",
    "        #push to cuda\n",
    "        if torch.cuda.is_available():\n",
    "            batch_x = batch_x.cuda()\n",
    "\n",
    "        #Forward pass\n",
    "        outputs = model(batch_x)\n",
    "\n",
    "        #converting the output to 1 Dimensional tensor\n",
    "        outputs = outputs.squeeze()\n",
    "\n",
    "        # convert to numpy array\n",
    "        prediction = outputs.data.cpu().numpy()\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "  # convert to single numpy array\n",
    "  predictions = np.concatenate(predictions, axis=0)\n",
    "    \n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e84fe2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 0 Training loss: 0.5341 \tTrain Accuracy: 0.845 \tValidation loss: 0.2164 \tValidation Accuracy: 0.9117\n",
      "\n",
      "----------------------------------------------------Saved best model------------------------------------------------------------------\n",
      "\n",
      "Epoch : 1 Training loss: 0.0912 \tTrain Accuracy: 0.9698 \tValidation loss: 0.1768 \tValidation Accuracy: 0.9348\n",
      "\n",
      "----------------------------------------------------Saved best model------------------------------------------------------------------\n",
      "\n",
      "Epoch : 2 Training loss: 0.0506 \tTrain Accuracy: 0.9862 \tValidation loss: 0.2137 \tValidation Accuracy: 0.9307\n",
      "\n",
      "Epoch : 3 Training loss: 0.0163 \tTrain Accuracy: 0.9964 \tValidation loss: 0.2776 \tValidation Accuracy: 0.9117\n",
      "\n",
      "Epoch : 4 Training loss: 0.014 \tTrain Accuracy: 0.9976 \tValidation loss: 0.2656 \tValidation Accuracy: 0.9198\n",
      "\n",
      "Epoch : 5 Training loss: 0.0076 \tTrain Accuracy: 0.9994 \tValidation loss: 0.2152 \tValidation Accuracy: 0.9307\n",
      "\n",
      "Epoch : 6 Training loss: 0.0098 \tTrain Accuracy: 0.9994 \tValidation loss: 0.2013 \tValidation Accuracy: 0.9361\n",
      "\n",
      "----------------------------------------------------Saved best model------------------------------------------------------------------\n",
      "\n",
      "Epoch : 7 Training loss: 0.004 \tTrain Accuracy: 0.9994 \tValidation loss: 0.2319 \tValidation Accuracy: 0.9321\n",
      "\n",
      "Epoch : 8 Training loss: 0.0066 \tTrain Accuracy: 0.9994 \tValidation loss: 0.2213 \tValidation Accuracy: 0.9389\n",
      "\n",
      "----------------------------------------------------Saved best model------------------------------------------------------------------\n",
      "\n",
      "Epoch : 9 Training loss: 0.0143 \tTrain Accuracy: 0.9982 \tValidation loss: 0.247 \tValidation Accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "batch_size = 32\n",
    "\n",
    "# intialization\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    #train the model\n",
    "    train_loss, train_acc  = train(X_train, y_train, batch_size)\n",
    "    \n",
    "    #evaluate the model\n",
    "    valid_loss, valid_acc = evaluate(X_valid, y_valid, batch_size)\n",
    "\n",
    "    print('\\nEpoch :',epoch,\n",
    "          'Training loss:',round(train_loss,4),\n",
    "          '\\tTrain Accuracy:',round(train_acc,4),\n",
    "          '\\tValidation loss:',round(valid_loss,4),\n",
    "          '\\tValidation Accuracy:',round(valid_acc,4))\n",
    "\n",
    "    #save the best model\n",
    "    if best_valid_acc <= valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt') \n",
    "        print(\"\\n----------------------------------------------------Saved best model------------------------------------------------------------------\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "894c1fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path='saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "30e72202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 93.88586956521739\n"
     ]
    }
   ],
   "source": [
    "valid_loss, valid_accuracy = evaluate(X_valid,y_valid,batch_size)\n",
    "\n",
    "print(\"Validation Accuracy:\",(valid_accuracy)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9ac922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
